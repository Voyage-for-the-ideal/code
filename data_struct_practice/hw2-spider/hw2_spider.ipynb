{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 使用python获取第一页html内容并解码为文本串，以utf8编码格式写入page1.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.nature.com/search?q=llm&order=relevance&date_range=2023-2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url =\"https://www.nature.com/search?q=llm&order=relevance&date_range=2023-2024\"\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    html_content=response.text\n",
    "    file_path=\"page1.txt\"\n",
    "    with open(file_path,\"w\",encoding=\"utf-8\") as file:\n",
    "        file.write(html_content)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 打开page1.txt，提取论文相关信息（标题，地址，简介，作者列表，文章类型，期刊名称，卷宗），按照期刊名进行分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "期刊 Nature Machine Intelligence 包含 6 篇论文\n",
      "期刊 Nature Communications 包含 10 篇论文\n",
      "期刊 Scientific Reports 包含 12 篇论文\n",
      "期刊 Nature Methods 包含 1 篇论文\n",
      "期刊 npj Digital Medicine 包含 3 篇论文\n",
      "期刊 Nature Medicine 包含 2 篇论文\n",
      "期刊 Nature 包含 4 篇论文\n",
      "期刊 Nature Human Behaviour 包含 2 篇论文\n",
      "期刊 npj Precision Oncology 包含 1 篇论文\n",
      "期刊 Nature Computational Science 包含 2 篇论文\n",
      "期刊 BDJ Open 包含 1 篇论文\n",
      "期刊 Nature Reviews Urology 包含 1 篇论文\n",
      "期刊 Communications Materials 包含 1 篇论文\n",
      "期刊 Humanities and Social Sciences Communications 包含 1 篇论文\n",
      "期刊 npj Biodiversity 包含 1 篇论文\n",
      "期刊 Eye 包含 1 篇论文\n",
      "期刊 npj Computational Materials 包含 1 篇论文\n"
     ]
    }
   ],
   "source": [
    "file_path=\"page1.txt\"\n",
    "with open(file_path,\"r\",encoding=\"utf-8\") as file:\n",
    "    content=file.read()\n",
    "soup=BeautifulSoup(content,'html.parser')\n",
    "journal_dict={}#初始化字典\n",
    "papers=soup.find_all(\"article\")\n",
    "for paper in papers:\n",
    "    # 提取文章标题\n",
    "    title = paper.find(\"h3\").text.strip()\n",
    "    \n",
    "    # 提取文章地址\n",
    "    url = paper.find(\"a\")[\"href\"]\n",
    "    \n",
    "    # 提取文章简介\n",
    "    description = paper.find(\"p\")\n",
    "    if description:\n",
    "        description = description.text.strip()\n",
    "    else:\n",
    "        description = \"no description\"\n",
    "\n",
    "    # 提取作者列表\n",
    "    authors = paper.find_all(\"span\", itemprop=\"name\")\n",
    "    if authors:\n",
    "        authors = [author.text.strip() for author in authors]\n",
    "    else:\n",
    "        authors = []\n",
    "    # 提取文章类型\n",
    "    type_element= paper.find(\"span\", class_=\"c-meta__type\")\n",
    "    if type_element:\n",
    "        type=type_element.text.strip()\n",
    "    else:\n",
    "        type=\"\"\n",
    "\n",
    "    # 提取期刊名称\n",
    "    journal_element = paper.find(\"div\", class_=\"c-meta__item c-meta__item--block-at-lg u-text-bold\")\n",
    "    if journal_element:\n",
    "        journal=journal_element.text.strip()\n",
    "    else:\n",
    "        journal=\"\"\n",
    "\n",
    "    # 提取卷宗/页面信息\n",
    "    volume_page_info = paper.find(\"div\", class_=\"c-meta__item c-meta__item--block-at-lg\")\n",
    "    if volume_page_info:\n",
    "        volume_page_info = volume_page_info.text.strip()\n",
    "    else:\n",
    "        volume_page_info = \"\"\n",
    "    if journal in journal_dict:\n",
    "        journal_dict[journal][\"papers\"].append({\n",
    "            \"title\": title,\n",
    "            \"authors\": authors,\n",
    "            \"url\": url,\n",
    "            \"description\": description,\n",
    "            \"type\": type,\n",
    "            \"volume_page_info\": volume_page_info\n",
    "        })\n",
    "    else:\n",
    "        journal_dict[journal] = {\n",
    "            \"journal\": journal,\n",
    "            \"papers\": [{\n",
    "                \"title\": title,\n",
    "                \"authors\": authors,\n",
    "                \"url\": url,\n",
    "                \"description\": description,\n",
    "                \"type\": type,\n",
    "                \"volume_page_info\": volume_page_info\n",
    "            }]\n",
    "        }\n",
    "for journal in journal_dict.values():\n",
    "    print(f\"期刊 {journal['journal']} 包含 {len(journal['papers'])} 篇论文\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bs4中find()和find_all()可能的报错\n",
    "\n",
    "`title = paper.find(\"h3\").text.strip()`\n",
    "\n",
    "如果paper.find(\"h3\")未查找到，则会返回none\n",
    "而none被text作用会报错\n",
    "\n",
    "**解决方法**：添加if检查\n",
    "#### find()用法\n",
    "不要直接使用AI生成的代码，应该直接查找html格式中具体每个标签是什么"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 将上一步字典中提取内容中的作者列表中的内容替换为文章主页显示的全部作者。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基于上述结果，输出每个期刊在page1中包含的论文数量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从page1.txt中提取每篇文章的链接，从链接中获取全部作者，替换journal_dict中每篇文章的作者。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url=\"https://www.nature.com\"\n",
    "for journal1 in journal_dict:\n",
    "    for paper in journal_dict[journal1]['papers']:\n",
    "        paper_url=paper['url']\n",
    "        full_url=base_url+paper_url\n",
    "        response = requests.get(full_url)\n",
    "        if response.status_code == 200:\n",
    "            html_content=response.text\n",
    "            soup=BeautifulSoup(html_content,'html.parser')\n",
    "            authors_meta = soup.find_all('meta', {'name': 'citation_author'})\n",
    "            if authors_meta:\n",
    "                authors = [f\"{meta['content'].split(', ')[1]} {meta['content'].split(', ')[0]}\" \n",
    "                      for meta in authors_meta]\n",
    "                paper[\"authors\"]=authors  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**如何遍历各个论文中的url？**\n",
    "1. 首先对`journal_dict`遍历，得到各个期刊名字的序号\n",
    "2. 再对journal_dict`[journal1]['papers']`遍历，其中`journal1`是第一步中的变量，`'papers'`为字典中储存各个期刊中的论文的key\n",
    "3. 此时`paper`(第二部中的变量)['url']，即可根据paper在journal1及journal1在journal_dict这两次遍历跑遍各个论文"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"nature_llm.json\",\"w\",encoding=\"utf-8\") as f:\n",
    "    json.dump(journal_dict, f, indent=2, ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
