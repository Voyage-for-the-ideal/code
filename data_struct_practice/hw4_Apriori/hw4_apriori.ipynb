{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df =pd.read_csv(\"data.csv\",index_col=0)\n",
    "\n",
    "#Q1\n",
    "column_mapping= {\n",
    "    'SC155Q01HA': 'DeviceCount',\n",
    "    'SC155Q02HA': 'Bandwidth',\n",
    "    'SC155Q03HA': 'InstructionDevices',\n",
    "    'SC155Q04HA': 'ComputingPower',\n",
    "    'SC155Q05HA': 'Software'\n",
    "}\n",
    "df.rename(columns=column_mapping,inplace=True)\n",
    "#inplace=True表示直接在原数据上修改\n",
    "df=df[list(column_mapping.values())].dropna()\n",
    "#删除缺失值所在的行\n",
    "\n",
    "simplified_names = ['DeviceCount', 'Bandwidth', 'InstructionDevices', 'ComputingPower', 'Software']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2\n",
    "#构建索引\n",
    "ind2val = {}\n",
    "val2ind={}\n",
    "index = 0\n",
    "simplified_names = ['DeviceCount', 'Bandwidth', 'InstructionDevices', 'ComputingPower', 'Software']\n",
    "int_size=0\n",
    "\n",
    "for column in simplified_names:\n",
    "    unique_values = df[column].unique()\n",
    "    for value in unique_values:\n",
    "        ind2val[index] = f\"{column}={value}\"\n",
    "        val2ind[f\"{column}={value}\"] = index\n",
    "        index += 1\n",
    "        int_size+=1\n",
    "\n",
    "#替换特征值为索引\n",
    "df=df.apply(lambda x:x.map(lambda v:val2ind[f\"{x.name}={v}\"]))\n",
    "# print(df['Software'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: [([1], 12930), ([3], 12873), ([5], 11323), ([7], 12341), ([9], 13080)], 2: [([1, 3], 10637), ([1, 5], 10506), ([1, 7], 10357), ([1, 9], 10596), ([7, 9], 10705)]}\n",
      "{1: [([0], 7751), ([1], 12930), ([2], 7808), ([3], 12873), ([4], 9358), ([5], 11323), ([6], 8340), ([7], 12341), ([8], 7601), ([9], 13080)], 2: [([0, 2], 5515), ([0, 4], 6934), ([0, 6], 5767), ([0, 8], 5267), ([1, 3], 10637), ([1, 5], 10506), ([1, 7], 10357), ([1, 9], 10596), ([2, 4], 5856), ([2, 6], 5625), ([3, 5], 9371), ([3, 7], 10158), ([3, 9], 10223), ([4, 6], 6813), ([4, 8], 6068), ([5, 7], 9796), ([5, 9], 9790), ([6, 8], 5965), ([7, 9], 10705)], 3: [([0, 4, 6], 5452), ([1, 3, 5], 9079), ([1, 3, 7], 9142), ([1, 3, 9], 9139), ([1, 5, 7], 9294), ([1, 5, 9], 9306), ([1, 7, 9], 9387), ([3, 5, 7], 8563), ([3, 5, 9], 8445), ([3, 7, 9], 9099), ([4, 6, 8], 5253), ([5, 7, 9], 8975)], 4: [([1, 3, 5, 7], 8362), ([1, 3, 5, 9], 8245), ([1, 3, 7, 9], 8404), ([1, 5, 7, 9], 8622), ([3, 5, 7, 9], 7984)], 5: [([1, 3, 5, 7, 9], 7834)]}\n"
     ]
    }
   ],
   "source": [
    "#T2\n",
    "def count(dt, item):#计算item在dt中的出现次数\n",
    "    cnt = 0\n",
    "    for line in dt:\n",
    "        if set(item) & set(line) == set(item):\n",
    "            cnt += 1\n",
    "    return cnt\n",
    "\n",
    "def apriori(df,min_support,int_size):\n",
    "    dt=df.to_numpy()\n",
    "    N=len(dt)\n",
    "    frequent_itemsets={1:[]}\n",
    "    for i in range(int_size+1):\n",
    "        cnt=count(dt,[i])\n",
    "        if cnt>=min_support*N:\n",
    "            frequent_itemsets[1].append(([i],cnt))\n",
    "    #求每个数字的出现次数并筛选，即1阶频繁项集的候选集\n",
    "    k=2\n",
    "    while True:\n",
    "        candidates=[]\n",
    "        frequent_new=[]\n",
    "        #此处如果不用frequent_new,而直接用frequent_itemsets[k]，则会结果中会出现空集\n",
    "        for i in range(len(frequent_itemsets[k-1])-1):\n",
    "        #len(frequent_itemsets[k-2])表示1，2，3.。。阶频繁项集的长度\n",
    "        #-1以防止超出索引\n",
    "            for j in range(i+1,len(frequent_itemsets[k-1])):\n",
    "                if frequent_itemsets[k-1][i][0][:-1]==frequent_itemsets[k-1][j][0][:-1]:\n",
    "                    candidates.append(sorted(set(frequent_itemsets[k-1][i][0]) | set(frequent_itemsets[k-1][j][0])))\n",
    "                    #set()去重，|求并集，sorted()排序\n",
    "                    #得到k阶频繁项集的候选集\n",
    "        # candidates=pd.DataFrame(candidates)\n",
    "        for candidate in candidates:\n",
    "            cnt=count(dt,candidate)\n",
    "            #candidates.iloc[i,:]表示第i行的所有元素，是一个列表\n",
    "            if cnt>=min_support*N:\n",
    "                frequent_new.append((candidate,cnt))\n",
    "                #将k阶频繁项集的候选集加入到k阶频繁项集中\n",
    "        if len(frequent_new)==0:\n",
    "            break\n",
    "        else:\n",
    "            frequent_itemsets[k]=frequent_new\n",
    "        k+=1\n",
    "    return frequent_itemsets\n",
    "\n",
    "\n",
    "fre_half=apriori(df,0.5,int_size)\n",
    "fre_quarter=apriori(df,0.25,int_size)\n",
    "\n",
    "print(fre_half)\n",
    "print(fre_quarter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DeviceCount=0.0': 0, 'DeviceCount=1.0': 1, 'Bandwidth=0.0': 2, 'Bandwidth=1.0': 3, 'InstructionDevices=0.0': 4, 'InstructionDevices=1.0': 5, 'ComputingPower=0.0': 6, 'ComputingPower=1.0': 7, 'Software=0.0': 8, 'Software=1.0': 9}\n"
     ]
    }
   ],
   "source": [
    "#重新构建索引\n",
    "ind2val = {}\n",
    "val2ind={}\n",
    "index = 0\n",
    "int_size=0\n",
    "\n",
    "#先将原始取值简化\n",
    "for column in simplified_names:\n",
    "    unique_values = sorted(df[column].unique())\n",
    "    for value in unique_values:\n",
    "\n",
    "        if value==1 or value==2:\n",
    "            df[column]=df[column].replace(value,0)\n",
    "        elif value==3 or value==4:\n",
    "            df[column]=df[column].replace(value,1)\n",
    "        #将1和2替换为0，3和4替换为1\n",
    "\n",
    "for column in simplified_names:\n",
    "    unique_values = df[column].unique()\n",
    "    for value in unique_values:\n",
    "        ind2val[index] = f\"{column}={value}\"\n",
    "        val2ind[f\"{column}={value}\"] = index\n",
    "        index += 1\n",
    "        int_size+=1\n",
    "\n",
    "#替换特征值为索引\n",
    "df=df.apply(lambda x:x.map(lambda v:val2ind[f\"{x.name}={v}\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "关联规则 X -> {1}（置信度≥0.8）:\n",
      "规则 [3] → {1}: 置信度=0.83, 提升度=1.32\n",
      "规则 [5] → {1}: 置信度=0.93, 提升度=1.48\n",
      "规则 [7] → {1}: 置信度=0.84, 提升度=1.34\n",
      "规则 [9] → {1}: 置信度=0.81, 提升度=1.30\n"
     ]
    }
   ],
   "source": [
    "def get_support_count(freq_dict, itemset):\n",
    "    k = len(itemset)\n",
    "    if k not in freq_dict:\n",
    "        return 0\n",
    "    sorted_itemset = sorted(itemset)\n",
    "    for (items, cnt) in freq_dict[k]:\n",
    "        if items == sorted_itemset:\n",
    "            return cnt\n",
    "    return 0\n",
    "\n",
    "def extract_rules(freq_itemsets, Y, min_conf, N):\n",
    "    Y = [1]\n",
    "    rules = []\n",
    "    # 获取Y的支持数\n",
    "    y_support = get_support_count(freq_itemsets, Y)\n",
    "    if y_support == 0:\n",
    "        return rules\n",
    "  \n",
    "    # 遍历所有k≥2的频繁项集\n",
    "    for k in list(freq_itemsets.keys()):\n",
    "        if k < 2:\n",
    "            continue\n",
    "        for (itemset, support_XY) in freq_itemsets[k]:\n",
    "            if 1 in itemset:\n",
    "                X = sorted([item for item in itemset if item != 1])\n",
    "                if not X:\n",
    "                    continue\n",
    "                # 检查X是否为频繁项集\n",
    "                x_support = get_support_count(freq_itemsets, X)\n",
    "                if x_support == 0:\n",
    "                    continue\n",
    "                # 计算置信度\n",
    "                confidence = support_XY / x_support\n",
    "                if confidence >= min_conf:\n",
    "                    # 计算提升度\n",
    "                    lift = (support_XY * N) / (x_support * y_support)\n",
    "                    rules.append((X, confidence, lift))\n",
    "    return rules\n",
    "\n",
    "dt=df.to_numpy()\n",
    "# 假设N为数据集总行数\n",
    "N = len(dt)  # dt是df转换后的numpy数组\n",
    "\n",
    "# 从支持度0.25的频繁项集中提取规则\n",
    "rules = extract_rules(fre_half, Y=[1], min_conf=0.8, N=N)\n",
    "\n",
    "# 输出结果\n",
    "print(\"关联规则 X -> {1}（置信度≥0.8）:\")\n",
    "for (X, conf, lift) in rules:\n",
    "    print(f\"规则 {X} → {{1}}: 置信度={conf:.2f}, 提升度={lift:.2f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "关联规则 X -> {1}（置信度≥0.8）:\n",
      "规则 [3] → {1}: 置信度=0.83, 提升度=1.32\n",
      "规则 [5] → {1}: 置信度=0.93, 提升度=1.48\n",
      "规则 [7] → {1}: 置信度=0.84, 提升度=1.34\n",
      "规则 [9] → {1}: 置信度=0.81, 提升度=1.30\n"
     ]
    }
   ],
   "source": [
    "def get_support_count(freq_dict, itemset):\n",
    "    k = len(itemset)\n",
    "    if k not in freq_dict:\n",
    "        return 0\n",
    "    sorted_itemset = sorted(itemset)\n",
    "    for (items, cnt) in freq_dict[k]:\n",
    "        if items == sorted_itemset:\n",
    "            return cnt\n",
    "    return 0\n",
    "\n",
    "def extract_rules(freq_itemsets, Y, min_conf, N):\n",
    "    Y = [1]\n",
    "    rules = []\n",
    "    # 获取Y的支持数\n",
    "    y_support = get_support_count(freq_itemsets, Y)\n",
    "    if y_support == 0:\n",
    "        return rules\n",
    "  \n",
    "    # 遍历所有k≥2的频繁项集\n",
    "    for k in list(freq_itemsets.keys()):\n",
    "        if k < 2:\n",
    "            continue\n",
    "        for (itemset, support_XY) in freq_itemsets[k]:\n",
    "            if 1 in itemset:\n",
    "                X = sorted([item for item in itemset if item != 1])\n",
    "                if not X:\n",
    "                    continue\n",
    "                # 检查X是否为频繁项集\n",
    "                x_support = get_support_count(freq_itemsets, X)\n",
    "                if x_support == 0:\n",
    "                    continue\n",
    "                # 计算置信度\n",
    "                confidence = support_XY / x_support\n",
    "                if confidence >= min_conf:\n",
    "                    # 计算提升度\n",
    "                    lift = (support_XY * N) / (x_support * y_support)\n",
    "                    rules.append((X, confidence, lift))\n",
    "    return rules\n",
    "\n",
    "dt=df.to_numpy()\n",
    "# 假设N为数据集总行数\n",
    "N = len(dt)  # dt是df转换后的numpy数组\n",
    "\n",
    "# 从支持度0.25的频繁项集中提取规则\n",
    "rules = extract_rules(fre_half, Y=[1], min_conf=0.8, N=N)\n",
    "\n",
    "# 输出结果\n",
    "print(\"关联规则 X -> {1}（置信度≥0.8）:\")\n",
    "for (X, conf, lift) in rules:\n",
    "    print(f\"规则 {X} → {{1}}: 置信度={conf:.2f}, 提升度={lift:.2f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "范围都是1-4\n",
    "SC155Q01HA\n",
    "The number of digital devices \n",
    "connected to the Internet is sufficient\n",
    "\n",
    "SC155Q02HA\n",
    "The school’s Internet bandwidth or speed is sufficient \n",
    "\n",
    "SC155Q03HA\n",
    "The number of digital devices for instruction is sufficient\n",
    "\n",
    "\n",
    "SC155Q04HA\n",
    "Digital devices at the school are sufficiently powerful in terms of computing capacity\n",
    "\n",
    "SC155Q05HA\n",
    "The availability of adequate software is sufficient "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
