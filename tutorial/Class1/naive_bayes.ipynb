{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Load the Iris dataset\n",
    "# The Iris dataset from sklearn is pre - embedded in the library, no need for additional downloads.\n",
    "iris = load_iris()\n",
    "# Features of the dataset\n",
    "X = iris.data\n",
    "# Target labels of the dataset\n",
    "y = iris.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "# test_size=0.3 means 30% of the data will be used as the test set.\n",
    "# random_state=42 ensures reproducibility of the split.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n:Number of Instances: 150 (50 in each of three classes)\\n:Number of Attributes: 4 numeric, predictive attributes and the class\\n:Attribute Information:\\n    - sepal length in cm\\n    - sepal width in cm\\n    - petal length in cm\\n    - petal width in cm\\n    - class:\\n            - Iris-Setosa\\n            - Iris-Versicolour\\n            - Iris-Virginica\\n\\n:Summary Statistics:\\n\\n============== ==== ==== ======= ===== ====================\\n                Min  Max   Mean    SD   Class Correlation\\n============== ==== ==== ======= ===== ====================\\nsepal length:   4.3  7.9   5.84   0.83    0.7826\\nsepal width:    2.0  4.4   3.05   0.43   -0.4194\\npetal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\npetal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n============== ==== ==== ======= ===== ====================\\n\\n:Missing Attribute Values: None\\n:Class Distribution: 33.3% for each of 3 classes.\\n:Creator: R.A. Fisher\\n:Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n:Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. dropdown:: References\\n\\n  - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n    Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n    Mathematical Statistics\" (John Wiley, NY, 1950).\\n  - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n    (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n  - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n    Structure and Classification Rule for Recognition in Partially Exposed\\n    Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n    Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n  - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n    on Information Theory, May 1972, 431-433.\\n  - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n    conceptual clustering system finds 3 classes in the data.\\n  - Many, many more ...\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.DESCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 基本信息：\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 6 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   sepal length (cm)  150 non-null    float64\n",
      " 1   sepal width (cm)   150 non-null    float64\n",
      " 2   petal length (cm)  150 non-null    float64\n",
      " 3   petal width (cm)   150 non-null    float64\n",
      " 4   target             150 non-null    int32  \n",
      " 5   target_name        150 non-null    object \n",
      "dtypes: float64(4), int32(1), object(1)\n",
      "memory usage: 6.6+ KB\n",
      "数据前几行内容信息：\n",
      "\tsepal length (cm)\tsepal width (cm)\tpetal length (cm)\tpetal width (cm)\ttarget\ttarget_name\n",
      "0\t5.1\t3.5\t1.4\t0.2\t0\tsetosa\n",
      "1\t4.9\t3.0\t1.4\t0.2\t0\tsetosa\n",
      "2\t4.7\t3.2\t1.3\t0.2\t0\tsetosa\n",
      "3\t4.6\t3.1\t1.5\t0.2\t0\tsetosa\n",
      "4\t5.0\t3.6\t1.4\t0.2\t0\tsetosa\n",
      "\n",
      "数据统计信息：\n",
      "\tsepal length (cm)\tsepal width (cm)\tpetal length (cm)\tpetal width (cm)\ttarget\n",
      "count\t150.0\t150.0\t150.0\t150.0\t150.0\n",
      "mean\t5.843333333333334\t3.0573333333333337\t3.7580000000000005\t1.1993333333333336\t1.0\n",
      "std\t0.828066127977863\t0.4358662849366982\t1.7652982332594662\t0.7622376689603465\t0.8192319205190405\n",
      "min\t4.3\t2.0\t1.0\t0.1\t0.0\n",
      "25%\t5.1\t2.8\t1.6\t0.3\t0.0\n",
      "50%\t5.8\t3.0\t4.35\t1.3\t1.0\n",
      "75%\t6.4\t3.3\t5.1\t1.8\t2.0\n",
      "max\t7.9\t4.4\t6.9\t2.5\t2.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "iris_df['target'] = iris.target\n",
    "target_mapping = {i: name for i, name in enumerate(iris.target_names)}\n",
    "iris_df['target_name'] = iris_df['target'].map(target_mapping)\n",
    "print(\"DataFrame 基本信息：\")\n",
    "iris_df.info()\n",
    "rows, columns = iris_df.shape\n",
    "print(\"数据前几行内容信息：\")\n",
    "print(iris_df.head().to_csv(sep='\\t', na_rep='nan'))\n",
    "print(\"数据统计信息：\")\n",
    "print(iris_df.describe().to_csv(sep='\\t', na_rep='nan'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Self - implemented Naive Bayes classifier\n",
    "class BayesClassifier:\n",
    "    def __init__(self):\n",
    "        # Store the unique classes in the dataset\n",
    "        self.classes = None\n",
    "        # Store the mean values of each feature for each class\n",
    "        self.mean = None\n",
    "        # Store the variance values of each feature for each class\n",
    "        self.var = None\n",
    "        # Store the prior probabilities of each class\n",
    "        self.priors = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Get the number of samples and features in the dataset\n",
    "        n_samples, n_features = X.shape\n",
    "        # Find all unique classes in the target labels\n",
    "        self.classes = np.unique(y)\n",
    "        # Get the number of unique classes\n",
    "        n_classes = len(self.classes)\n",
    "\n",
    "        # Initialize arrays to store mean, variance, and prior probabilities\n",
    "        self.mean = np.zeros((n_classes, n_features))\n",
    "        self.var = np.zeros((n_classes, n_features))\n",
    "        self.priors = np.zeros(n_classes)\n",
    "\n",
    "        # Calculate the mean, variance, and prior probability for each class\n",
    "        for idx, c in enumerate(self.classes):\n",
    "            # Extract samples belonging to the current class\n",
    "            X_c = X[y == c]\n",
    "            # Calculate the mean of each feature for the current class\n",
    "            self.mean[idx, :] = X_c.mean(axis=0)\n",
    "            # Calculate the variance of each feature for the current class\n",
    "            self.var[idx, :] = X_c.var(axis=0)\n",
    "            # Calculate the prior probability of the current class\n",
    "            self.priors[idx] = X_c.shape[0] / float(n_samples)\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Make predictions for each sample in the input data\n",
    "        y_pred = [self._predict(x) for x in X]\n",
    "        return np.array(y_pred)\n",
    "\n",
    "    def _predict(self, x):\n",
    "        # Store the posterior probabilities for each class\n",
    "        posteriors = []\n",
    "\n",
    "        # Calculate the posterior probability for each class\n",
    "        for idx, c in enumerate(self.classes):\n",
    "            # Calculate the log of the prior probability\n",
    "            prior = np.log(self.priors[idx])\n",
    "            # Calculate the log of the class - conditional probability\n",
    "            class_conditional = np.sum(np.log(self._pdf(idx, x)))\n",
    "            # Calculate the posterior probability\n",
    "            posterior = prior + class_conditional\n",
    "            posteriors.append(posterior)\n",
    "\n",
    "        # Return the class with the maximum posterior probability\n",
    "        return self.classes[np.argmax(posteriors)]\n",
    "    \n",
    "    def _pdf(self, class_idx, x):\n",
    "        # Mean values of features for the specified class\n",
    "        mean = self.mean[class_idx]\n",
    "        # Variance values of features for the specified class\n",
    "        var = self.var[class_idx]\n",
    "        # Numerator of the Gaussian probability density function\n",
    "        numerator = np.exp(- (x - mean) ** 2 / (2 * var))\n",
    "        # Denominator of the Gaussian probability density function\n",
    "        denominator = np.sqrt(2 * np.pi * var)\n",
    "        return numerator / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.67%\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the Naive Bayes classifier\n",
    "model = BayesClassifier()\n",
    "# Train the classifier using the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the predictions\n",
    "accuracy = np.sum(y_pred == y_test) / len(y_test)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
